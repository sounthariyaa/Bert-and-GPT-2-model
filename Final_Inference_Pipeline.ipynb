{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference_Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCSSY_pc7g3y",
        "outputId": "d7a4546e-e5fc-4755-b348-797a4a8b23df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXvSKCv87iHH",
        "outputId": "ba01725d-900f-45d7-9af1-188cf06f6709"
      },
      "source": [
        "cd 'drive/My Drive/chatbot'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvYpYyI8ixT",
        "outputId": "e384dd55-f62a-4e31-b0a8-5bd1681044f3"
      },
      "source": [
        "#installing transformers library\r\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 18.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=03b88a17dc29774cc85b6f85ce142fddb600526fab8482dbf572971383458538\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpCd0T2FFi7F",
        "outputId": "e1ae396e-eb52-466a-cc70-6b1f490c150b"
      },
      "source": [
        "#installing faiss and other related libraries\n",
        "!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-13 05:04:31--  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
            "Resolving anaconda.org (anaconda.org)... 104.17.92.24, 104.17.93.24, 2606:4700::6811:5c18, ...\n",
            "Connecting to anaconda.org (anaconda.org)|104.17.92.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9c5c376961204909d87/5aa7f0a65571b411e5c259be?response-content-disposition=attachment%3B%20filename%3D%22faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20210213T050432Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDbD%2BYMdUcFJGT6c7AzZOfatlmAbpUWefPZb1Al0b0XgQIgPPpZ2N3WkHhYNGiuoQ4eaoBiffXXLWIc3TwwzuaWOxIqvQMI4v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw0NTU4NjQwOTgzNzgiDDpNz06jeGQzHZPNQiqRA6XQee9TXd4V5XjgMk%2BUVwBvoStQRnDI4R%2FhKjjoNlaRqpcOvhcdFJghU2U8fE8z%2FlLGKhLBfLp2ISXw4u%2FwbJtp7ek317Goc0UNiMAJRzh2iJ4HrCiSWygCcZvJACo5Z6CA6u7liaxzAMCP22BUkwvcev571WHdETVw721KlwD7tBlrcyvqnJNBs%2F%2FwOIHhfaqwO5zTYoVkHrVqEDr3nYzqps%2F4FeU3B7x%2FnEutlDlsurenzz%2BUTuV8sXVCvZpTpIvnfjabpYFQTijs8ohu8PTGH5a4ZJRgJ5kRv8m23xmr9GmSPEun%2F4MREdh1MfYuQzmCf51iDv8ciMnwdSOuE1Ypbj%2BehO7757uSAA9%2BjEFXtyH54tRdZPZ51awU293%2Bz6%2F1tzgmvWSK0%2BMAwEMrx3hAHrA%2F0fZgxex8x2RMFAFPwUqWsnO7ByNgXOLFuAWp%2F9V3igfS4Nc3cjJOkBQUSseVj1IqX%2B76bJQeNHsS6S1dE0492DkjFDG%2B5fvYrqMPtLCYgLVtPZMFHG5OppBE%2BaZvML3NnIEGOusB4gDxrxKH8qrFs5adf4Ow4TqWYKJdznBm73vljy9bMrUZCyAeP3tD0TrMmI%2B4siNQdZmwEHOjnBAPhuIqKj9QU1a%2FRujyBzA3SZBcUJD%2Bq3GAqQG6Gh01VP4L6sHqG8GYqDVb8BhooGVkjEsoteotng72uBrEmC5Z79a5UHqIK2FRHUsFumP18KmZjaLAiL1b0tWhDrwi%2BwcDk%2Fn8RFuO46RWh46QBK36V1mb4CQUU5wW9XLwR8NbccDbLbDd4%2Bg9AzkFivZ%2Bv2fUGMZBC7RU9yBVo5YAYpJ4J0lGwBV84TynQWYad4qLTfX1kA%3D%3D&X-Amz-Credential=ASIAWUI46DZFEMUTWQ5A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=2432aef3e2950474e27374fcd4adcad7f29acb7256b27b324b2ce7646b1671f8 [following]\n",
            "--2021-02-13 05:04:32--  https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9c5c376961204909d87/5aa7f0a65571b411e5c259be?response-content-disposition=attachment%3B%20filename%3D%22faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20210213T050432Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDbD%2BYMdUcFJGT6c7AzZOfatlmAbpUWefPZb1Al0b0XgQIgPPpZ2N3WkHhYNGiuoQ4eaoBiffXXLWIc3TwwzuaWOxIqvQMI4v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw0NTU4NjQwOTgzNzgiDDpNz06jeGQzHZPNQiqRA6XQee9TXd4V5XjgMk%2BUVwBvoStQRnDI4R%2FhKjjoNlaRqpcOvhcdFJghU2U8fE8z%2FlLGKhLBfLp2ISXw4u%2FwbJtp7ek317Goc0UNiMAJRzh2iJ4HrCiSWygCcZvJACo5Z6CA6u7liaxzAMCP22BUkwvcev571WHdETVw721KlwD7tBlrcyvqnJNBs%2F%2FwOIHhfaqwO5zTYoVkHrVqEDr3nYzqps%2F4FeU3B7x%2FnEutlDlsurenzz%2BUTuV8sXVCvZpTpIvnfjabpYFQTijs8ohu8PTGH5a4ZJRgJ5kRv8m23xmr9GmSPEun%2F4MREdh1MfYuQzmCf51iDv8ciMnwdSOuE1Ypbj%2BehO7757uSAA9%2BjEFXtyH54tRdZPZ51awU293%2Bz6%2F1tzgmvWSK0%2BMAwEMrx3hAHrA%2F0fZgxex8x2RMFAFPwUqWsnO7ByNgXOLFuAWp%2F9V3igfS4Nc3cjJOkBQUSseVj1IqX%2B76bJQeNHsS6S1dE0492DkjFDG%2B5fvYrqMPtLCYgLVtPZMFHG5OppBE%2BaZvML3NnIEGOusB4gDxrxKH8qrFs5adf4Ow4TqWYKJdznBm73vljy9bMrUZCyAeP3tD0TrMmI%2B4siNQdZmwEHOjnBAPhuIqKj9QU1a%2FRujyBzA3SZBcUJD%2Bq3GAqQG6Gh01VP4L6sHqG8GYqDVb8BhooGVkjEsoteotng72uBrEmC5Z79a5UHqIK2FRHUsFumP18KmZjaLAiL1b0tWhDrwi%2BwcDk%2Fn8RFuO46RWh46QBK36V1mb4CQUU5wW9XLwR8NbccDbLbDd4%2Bg9AzkFivZ%2Bv2fUGMZBC7RU9yBVo5YAYpJ4J0lGwBV84TynQWYad4qLTfX1kA%3D%3D&X-Amz-Credential=ASIAWUI46DZFEMUTWQ5A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=2432aef3e2950474e27374fcd4adcad7f29acb7256b27b324b2ce7646b1671f8\n",
            "Resolving binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)... 52.216.98.123\n",
            "Connecting to binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)|52.216.98.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4106816 (3.9M) [application/x-tar]\n",
            "Saving to: ‘faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2.6’\n",
            "\n",
            "faiss-cpu-1.2.1-py3 100%[===================>]   3.92M  2.69MB/s    in 1.5s    \n",
            "\n",
            "2021-02-13 05:04:34 (2.69 MB/s) - ‘faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2.6’ saved [4106816/4106816]\n",
            "\n",
            "info/hash_input.json\n",
            "info/has_prefix\n",
            "info/index.json\n",
            "info/git\n",
            "info/files\n",
            "info/LICENSE.txt\n",
            "info/about.json\n",
            "info/paths.json\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/dependency_links.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/not-zip-safe\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/requires.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/top_level.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/native_libs.txt\n",
            "info/test/run_test.py\n",
            "info/test/run_test.sh\n",
            "info/test/tests/run_tests.sh\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/SOURCES.txt\n",
            "info/recipe/conda_build_config.yaml\n",
            "info/recipe/build.sh\n",
            "info/test/tests/CMakeLists.txt\n",
            "info/test/tests/Makefile\n",
            "info/recipe/meta.yaml.template\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/PKG-INFO\n",
            "info/test/tests/test_factory.py\n",
            "info/test/tests/test_ivfpq_codec.cpp\n",
            "info/recipe/meta.yaml\n",
            "info/recipe/setup.py\n",
            "info/test/tests/test_blas.cpp\n",
            "info/recipe/makefile.inc\n",
            "info/test/tests/test_ivfpq_indexing.cpp\n",
            "info/test/tests/test_ondisk_ivf.cpp\n",
            "info/test/tests/test_build_blocks.py\n",
            "info/test/tests/test_merge.cpp\n",
            "info/test/tests/test_pairs_decoding.cpp\n",
            "info/test/tests/test_index_composite.py\n",
            "lib/python3.6/site-packages/faiss/__init__.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/__init__.cpython-36.pyc\n",
            "info/test/tests/test_index.py\n",
            "info/test/tests/test_blas\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss.py\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss.so\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from mkl) (2021.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Vab-F67vvT"
      },
      "source": [
        "#importing other necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import faiss\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APu3tIzp8-i7"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX9tdGFM0z1v",
        "outputId": "84f6ed68-d69d-494c-82ee-0075d576f356"
      },
      "source": [
        "#importing bert tokenizer and loading the trained question embedding extractor model\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "biobert_tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/BioRedditBERT-uncased\")\n",
        "question_extractor_model1=tf.keras.models.load_model('question_extractor_model_2_11')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KJ4asMSGY1o",
        "outputId": "f6e85014-e5b7-451a-805e-97602b8d15dd"
      },
      "source": [
        "#importing gpt2 tokenizer and loading the trained gpt2 model\n",
        "from transformers import GPT2Tokenizer,TFGPT2LMHeadModel\n",
        "gpt2_tokenizer=GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tf_gpt2_model=TFGPT2LMHeadModel.from_pretrained(\"./tf_gpt2_model_2_105_130000\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./tf_gpt2_model_2_105_130000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anSHKufoF21T"
      },
      "source": [
        "#preparing the faiss search\n",
        "qa=pd.read_pickle('./train_gpt_data.pkl')\n",
        "question_bert = qa[\"Q_FFNN_embeds\"].tolist()\n",
        "answer_bert = qa[\"A_FFNN_embeds\"].tolist()\n",
        "question_bert = np.array(question_bert)\n",
        "answer_bert = np.array(answer_bert)\n",
        "\n",
        "question_bert = question_bert.astype('float32')\n",
        "answer_bert = answer_bert.astype('float32')\n",
        "\n",
        "answer_index = faiss.IndexFlatIP(answer_bert.shape[-1])\n",
        "\n",
        "question_index = faiss.IndexFlatIP(question_bert.shape[-1])\n",
        "answer_index.add(answer_bert)\n",
        "question_index.add(question_bert)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1JOjY8ZGGGX"
      },
      "source": [
        "#defining function to prepare the data for gpt inference\n",
        "#https://github.com/ash3n/DocProduct\n",
        "def preparing_gpt_inference_data(question,question_embedding):\n",
        "  topk=20\n",
        "  scores,indices=answer_index.search(\n",
        "                  question_embedding.astype('float32'), topk)\n",
        "  q_sub=qa.iloc[indices.reshape(20)]\n",
        "  \n",
        "  line = '`QUESTION: %s `ANSWER: ' % (\n",
        "                        question)\n",
        "  encoded_len=len(gpt2_tokenizer.encode(line))\n",
        "  for i in q_sub.iterrows():\n",
        "    line='`QUESTION: %s `ANSWER: %s ' % (i[1]['question'],i[1]['answer']) + line\n",
        "    line=line.replace('\\n','')\n",
        "    encoded_len=len(gpt2_tokenizer.encode(line))\n",
        "    if encoded_len>=1024:\n",
        "      break\n",
        "  return gpt2_tokenizer.encode(line)[-1024:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4-xGtp8abb"
      },
      "source": [
        "#function to generate answer given a question and the required answer length\n",
        "def give_answer(question,answer_len):\n",
        "  preprocessed_question=preprocess(question)\n",
        "  question_len=len(preprocessed_question.split(' '))\n",
        "  truncated_question=preprocessed_question\n",
        "  if question_len>500:\n",
        "    truncated_question=' '.join(preprocessed_question.split(' ')[:500])\n",
        "  encoded_question= biobert_tokenizer.encode(truncated_question)\n",
        "  max_length=512\n",
        "  padded_question=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      [encoded_question], maxlen=max_length, padding='post')\n",
        "  question_mask=[[1 if token!=0 else 0 for token in question] for question in padded_question]\n",
        "  embeddings=question_extractor_model1({'question':np.array(padded_question),'question_mask':np.array(question_mask)})\n",
        "  gpt_input=preparing_gpt_inference_data(truncated_question,embeddings.numpy())\n",
        "  mask_start = len(gpt_input) - list(gpt_input[::-1]).index(4600) + 1\n",
        "  input=gpt_input[:mask_start+1]\n",
        "  if len(input)>(1024-answer_len):\n",
        "   input=input[-(1024-answer_len):]\n",
        "  gpt2_output=gpt2_tokenizer.decode(tf_gpt2_model.generate(input_ids=tf.constant([np.array(input)]),max_length=1024,temperature=0.7)[0])\n",
        "  answer=gpt2_output.rindex('`ANSWER: ')\n",
        "  return gpt2_output[answer+len('`ANSWER: '):]\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYrJlPpp9q_d"
      },
      "source": [
        "#defining the final function to generate answer assuming default answer length to be 20\r\n",
        "def final_func_1(question):\r\n",
        "  answer_len=25\r\n",
        "  return give_answer(question,answer_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbo4tj1O-LcR"
      },
      "source": [
        "#defining the final function to calculate the required metric answer assuming default answer length to be 20\r\n",
        "def final_func_2(question,answer):\r\n",
        "  answer_len=20\r\n",
        "  generated_answer=give_answer(question,answer_len)\r\n",
        "  reference = [answer.split(' ')]\r\n",
        "  candidate = generated_answer.split(' ')\r\n",
        "  score = sentence_bleu(reference, candidate)\r\n",
        "  return score"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyakBpU3_s30",
        "outputId": "2f62ae09-8b3a-4f79-8c16-2487f5c4db4d"
      },
      "source": [
        "#testing final_func1 on sample input\r\n",
        "answer=final_func_1('Hi how are you')\r\n",
        "print(\"answer:\",answer)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "answer: hi i am sorry to hear of your daughter is condition but i do not think it is due to anemia or anything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7szY4e0_xNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8134e1-5ec4-4626-9042-2ab30b418816"
      },
      "source": [
        "#testing final_fun2 on sample input\r\n",
        "metric=final_func_2('Hi how are you','I am fine')\r\n",
        "print(metric)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.47897362544357464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtgbKUlTAqMY"
      },
      "source": [
        "**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC-P4YoIAs8K"
      },
      "source": [
        "In this notebook we have implemented the end-end pipeline required for generating an answer to a question asked by a patient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7gajAXsA0-n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}